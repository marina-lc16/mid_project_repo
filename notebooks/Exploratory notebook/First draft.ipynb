{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4444bd7",
   "metadata": {},
   "source": [
    "# DATA SCIENCE JOBS: SALARIES AND TYPE OF WORKS MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842e4dab",
   "metadata": {},
   "source": [
    "## Project information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07652428",
   "metadata": {},
   "source": [
    "In recent years, data science roles are more demanded, so it's important to understand how they are evolving in terms of positioning as job offers and their salaries.\n",
    "\n",
    "In this analysis, I will take my first Exploratory Data Analysis (EDA) and visualization project using Python, where I explored data science salaries between 2020 and 2023. \n",
    "\n",
    "The \"global salary index\" dataset comes from the ai-jobs.net website for roles in the AI, ML, Data Science space based on internal data obtanided from surveys and jobs with open salaries.\n",
    "\n",
    "This dataset is processed and updated on a weekly basis but I'll take the dataset updated on September 29th, 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63937388",
   "metadata": {},
   "source": [
    "## Hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319ad9c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7eaf3bf9",
   "metadata": {},
   "source": [
    "## Understanding and preprocessing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e76d03",
   "metadata": {},
   "source": [
    "### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f0a959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff64f67b",
   "metadata": {},
   "source": [
    "### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35e569b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/raw/salaries.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/raw/salaries.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m500\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/raw/salaries.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/raw/salaries.csv')\n",
    "df.head(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff12641",
   "metadata": {},
   "source": [
    "### Dataset shape and information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26cf482",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows and columns in the dataset:\",df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb533c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Information about the dataset including the index dtype and columns, non-null values and memory usage\n",
    "      \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dc7437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate descriptive statistics\n",
    "      \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602d9bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring column names of the dataframe\n",
    "\n",
    "print(\"The column names of the dataset are::\\n\\n\",df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970e971f",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709713b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring if the dataset contains missing values\n",
    "\n",
    "df.isnull().sum()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2689e63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of missing data in the dataset:\",df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03471cc3",
   "metadata": {},
   "source": [
    "There is no missing data so it will not be necessary to delete any columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f2144e",
   "metadata": {},
   "source": [
    "### Unique values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b2176c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exploring unique values per each column of the dataset\n",
    "\n",
    "print(\"Number of unique values in columns:\\n\\n\", df.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4120f368",
   "metadata": {},
   "source": [
    "With this exploration we can highlight some columns with many unique values, it will be important to analyze if we can work with these data or we will have to group them to reduce the size of the dataset.\n",
    "\n",
    "- Job_title\n",
    "- Salary\n",
    "- Salary_in_usd\n",
    "- Employee_residence\n",
    "- Company location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f439b15a",
   "metadata": {},
   "source": [
    "### Overview data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1906e6a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "951ed0f8",
   "metadata": {},
   "source": [
    "________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fd4c5f",
   "metadata": {},
   "source": [
    "## Data cleaning or transform it\n",
    "\n",
    "Once we get all the overall information we can start working with the data and think about what changes we can make to clean up the data or transform it to ensure more meaningful consistency of certain values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe9c011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to create a copy of the original dataframe before doing any transformation on the original data\n",
    "# We will call the new df \"data_cleaning\" to recognize the process we are working with\n",
    "\n",
    "data_cleaning0 = df.copy()\n",
    "data_cleaning0.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31f3264",
   "metadata": {},
   "source": [
    "We will have to divide the dataset into numerical and categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97e99f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Before starting cleaning the numerical data we will need to transform the column \"remote_ratio\" into an object column\n",
    "\n",
    "data_cleaning = data_cleaning0.copy()\n",
    "data_cleaning['remote_ratio'] = data_cleaning['remote_ratio'].apply(str)\n",
    "\n",
    "data_cleaning.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e4b051",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e2a481",
   "metadata": {},
   "source": [
    "## Cleaning numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d502cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DataFrame with numericals columns\n",
    "\n",
    "numericals = data_cleaning.select_dtypes(np.number)\n",
    "numericals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52799673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check values dtypes\n",
    "\n",
    "numericals.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd82f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of distinct elements in the numericals DataFrame \n",
    "\n",
    "numericals.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875a79c1",
   "metadata": {},
   "source": [
    "### \"Work_year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8034dd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the unique values\n",
    "numericals[\"work_year\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3548a0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, ax = plt.subplots()\n",
    "sns.lineplot(x=numericals[\"work_year\"].value_counts().index, y=numericals[\"work_year\"].value_counts().values, ax = ax)\n",
    "ax.set_ylabel(\"Number of jobs posted\")\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.xaxis.set_minor_locator(ticker.MultipleLocator(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128ab077",
   "metadata": {},
   "source": [
    "### \"Salary\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc15b09",
   "metadata": {},
   "source": [
    "What we can take from this analysis is that there are two columns that have a number of values well above the rest, the salaries. In this case the data is duplicated because we have the same salary/job title in different currencies.\n",
    "\n",
    "As the analysis will not be focused on wage differentials between countries it's better to focus the analysis with the same currency for all job titles, in this case we have a column with salaries in USD and we will use it for clearer visibility.\n",
    "\n",
    "As a consequence, we will remove the \"salary\" column and change the name of the \"salary_in_usd\" column to \"salary\".\n",
    "\n",
    "- \"salary\"\n",
    "- \"salary_in_usd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422786e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop \"salary\" column\n",
    "\n",
    "numericals.drop(labels=[\"salary\"], axis=1, inplace=True)\n",
    "numericals.rename(columns={\"salary_in_usd\": \"salary\"}, inplace=True)\n",
    "\n",
    "numericals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3654a8",
   "metadata": {},
   "source": [
    "## Qualitative approaches to detect outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb3b699",
   "metadata": {},
   "source": [
    "Technique to identify uni-dimensional outliers is to create a boxplot and to see if\n",
    "there are isolated dots quite far away from the wiskers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6062fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#work_year\n",
    "\n",
    "fig, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\":(.15, .85)})\n",
    "sns.boxplot(data=numericals, x=\"work_year\", ax=ax_box) #display boxplot\n",
    "sns.histplot(data=numericals, x=\"work_year\", ax=ax_hist) #hist of the same column\n",
    "ax.set_ylabel(\"Number of jobs posted\")\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.xaxis.set_minor_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe9cdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the skewness\n",
    "(numericals['work_year'].skew() > 2) or (numericals['work_year'].skew() < -2), numericals['work_year'].skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd0fc22",
   "metadata": {},
   "source": [
    "We have a negative skew on the \"work_year\" column.\n",
    "That means a longer tail on the left side of the distribution, or in other words, is the direction or weight of the distribution. \n",
    "\n",
    "We have more values from 2023 on our dataset, and just few from 2020 (outliers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab425667",
   "metadata": {},
   "outputs": [],
   "source": [
    "#salary\n",
    "\n",
    "fig, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\":(.15, .85)})\n",
    "sns.boxplot(data=numericals, x=\"salary\", ax=ax_box) #display boxplot\n",
    "sns.histplot(data=numericals, x=\"salary\", ax=ax_hist) #hist of the same column\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bad97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the skewness\n",
    "(numericals['salary'].skew() > 2) or (numericals['salary'].skew() < -2), numericals['salary'].skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaf0938",
   "metadata": {},
   "source": [
    "For the \"salary\" column we have a little positive skew.\n",
    "That means a longer tail on the right side of the distribution.\n",
    "Just few salaries are between 30-40K."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a335eaa7",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829e69f4",
   "metadata": {},
   "source": [
    "## Cleaning categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00433c2",
   "metadata": {},
   "source": [
    "Now, we will proceed to pre-processing the categorical data (clean and transformed).\n",
    "\n",
    "Transform categorical data (encoded) https://www.datacamp.com/tutorial/categorical-data\n",
    "\n",
    "Confirm if it's necessary or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c894e9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DataFrame with categoricals columns\n",
    "\n",
    "categoricals = data_cleaning.select_dtypes([object])\n",
    "categoricals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a3b162",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27431f8",
   "metadata": {},
   "source": [
    "Looking at the values included in each column we can see that some of them may be confusing, the current values  don't help us to understand the real meaning.\n",
    "\n",
    "The columns affected are:\n",
    "\n",
    "- \"experience_level\"\n",
    "- \"employment_type\"\n",
    "- \"employee_residence\"\n",
    "- \"remote_ratio\"\n",
    "- \"company_location\"\n",
    "- \"company_size\"\n",
    "\n",
    "We will need to evaluate individually to define if we need to replace or group them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea230f77",
   "metadata": {},
   "source": [
    "### \"Experience_level\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55211c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the unique values\n",
    "categoricals[\"experience_level\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff0edb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"We know that the real meanings per each value are:\n",
    "    SE - Senior\n",
    "    MI - Mid\n",
    "    EN - Entry\n",
    "    EX - Executive\n",
    "    \n",
    "    We need to apply a <.replace> to replace each value with its real meaning \"\"\"\n",
    "\n",
    "replace_cat = categoricals.copy()\n",
    "replace_cat.experience_level.replace(['EN','MI','SE', 'EX'], ['entry', 'mid', 'senior', 'executive'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61f76e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the substitution has been applied correctly\n",
    "\n",
    "replace_cat[\"experience_level\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f58162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  create a plot with Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc86c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63195ae8",
   "metadata": {},
   "source": [
    "### \"Employment_type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c1c188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the unique values\n",
    "categoricals[\"employment_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecc396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"We know that the real meanings per each value are:\n",
    "    FT - Full_time\n",
    "    CT - Contract\n",
    "    PT - Part_Time\n",
    "    FL - Freelance\n",
    "    \n",
    "    We need to apply a <.replace> to replace each value with its real meaning \"\"\"\n",
    "\n",
    "replace_cat.employment_type.replace(['FT','CT' , 'PT', 'FL'], ['full_time', 'contract', 'part_Time', 'freelance'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d01c40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_cat['employment_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a82879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f77154",
   "metadata": {},
   "source": [
    "### \"Remote_ratio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc388a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the unique values\n",
    "categoricals[\"remote_ratio\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718d1d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"We know that the real meanings per each value are:\n",
    "    0 - No_remote/On_site\n",
    "    50 - Hybrid\n",
    "    100 - Remote\n",
    "    \n",
    "    We need to apply a <.replace> to replace each value with its real meaning \"\"\"\n",
    "\n",
    "replace_cat.remote_ratio.replace(['0','50','100'], ['on_site', 'hybrid', 'remote'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e964798",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_cat['remote_ratio'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a503154f",
   "metadata": {},
   "outputs": [],
   "source": [
    " # create a plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e81826",
   "metadata": {},
   "source": [
    "### \"Company_size\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd44af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the unique values\n",
    "categoricals[\"company_size\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ae03a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"We know that the real meanings per each value are:\n",
    "    S - small\n",
    "    M - medium\n",
    "    L - marge\n",
    "    \n",
    "    We need to apply a <.replace> to replace each value with its real meaning \"\"\"\n",
    "\n",
    "replace_cat.company_size.replace(['S','M','L'], ['small', 'medium', 'large'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc95e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_cat[\"company_size\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138ee7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    " # create a plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36b34e3",
   "metadata": {},
   "source": [
    "### \"Salary_currency\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04577d08",
   "metadata": {},
   "source": [
    "As mentioned above, the salary analysis will be done only with USD currency, that is why we can delete the column \"salary_currency\" to avoid having data that could create interferences in our analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286d7000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the unique values\n",
    "categoricals[\"salary_currency\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d995ed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_cat.drop([\"salary_currency\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ea3cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the column has been dropped correctly\n",
    "\n",
    "replace_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c8a746",
   "metadata": {},
   "outputs": [],
   "source": [
    " # create a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e570301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfed349e",
   "metadata": {},
   "source": [
    "### \"Employee_residence\" & \"Company_location\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170dbeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique values in employee_residence column is:\\n\\n\", categoricals[\"employee_residence\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bb6f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique values in company_locations column is:\\n\\n\", categoricals[\"company_location\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2717ec63",
   "metadata": {},
   "source": [
    "We want to replace the codes for locations or country names\n",
    "\n",
    "Python has a function called \"pycountry\" (https://pypi.org/project/pycountry/) that provides the ISO databases for countries and others. We know that the <codes> in our database are encoded based on the \"ISO\" because it's specified in the \"Legend\" in the web from where we have extracted the database (https://ai-jobs.net/salaries/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c487bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"We want to replace the locations and countries residence codes \n",
    "for employees and companies to reduce the values size.\n",
    "\n",
    "We will need to use a For Loop to go from code to code and create a new list with the new value names.\n",
    "\n",
    "We will need to use the library \"pycountry\":\n",
    "\n",
    "#Convert country code ISO 3166-1 alpha-2 to country name:\n",
    "#country_alpha2_to_country_name(cn_name_format=\"default\") \n",
    "\"\"\"\n",
    "\n",
    "from pycountry import countries\n",
    "\n",
    "employee_country = []\n",
    "company_country = []\n",
    "\n",
    "for country_code in replace_cat.employee_residence:\n",
    "   employee_country.append(pycountry.countries.get(alpha_2=country_code).name)\n",
    "\n",
    "for country_code in replace_cat.company_location:\n",
    "    company_country.append(pycountry.countries.get(alpha_2=country_code).name)\n",
    "\n",
    "replace_cat['employee_residence'] = employee_country\n",
    "replace_cat['company_location'] = company_country\n",
    "\n",
    "\n",
    "#https://snyk.io/advisor/python/pycountry/functions/pycountry.countries.get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5e5b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the replacement from country code to coutnry names has ben placed correctly\n",
    "\n",
    "replace_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ce41a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93e4110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895183ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01f51ff2",
   "metadata": {},
   "source": [
    "### \"Job_title\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b715e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the unique values\n",
    "categoricals[\"job_title\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9892d15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma\n",
    "fig= plt.subplots\n",
    "sns.histplot(y=\"job_title\", data=replace_cat);\n",
    "ax.set_title(\"Jobs per work year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceec356",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment_mbp",
   "language": "python",
   "name": "environment_mbp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
